{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear diferentes Notebooks para cada proceso realizado.\n",
    "\n",
    "EDA (dimensiones y tipos de columnas del df, número de NA por columnas y por filas (sacar la proporción de ambos casos), histogramas de cada una de las variables, correlaciones de las diferentes variables, correlaciones de cada grupo por separado). Sacar otras ideas de otros Notebooks de EDA de Kaggle.\n",
    "\n",
    "Diferentes métodos simples (Simple Imputer, KNN Imputer, Iterative Imputer). Fijarme en los Notebooks subidos en Kaggle para utilizar alguno para explicar mejor la parte más teórica.\n",
    "\n",
    "LigthGBM (Toda la parte de código usada de ARShaik). Conclusiones sacadas de que solo merece la pena entrenar con las columnas F4. El resto no tiene apenas cambio de utilizar otros metodos mas simples, tampoco influye para mejorar usar el resto de columnas (F1, F2 & F3) para predecir las columnas F4.\n",
    "\n",
    "NN (Toda la parte de código usada de C4rl05/V). Seguimos con la suposición de que es mejor centrarse en mejorar únicamente el performance de las columnas F4. Probar las diferentes suposiciones entrenando los modelos para cada columna con todo el dataset cambiando los NA por valores medios en dicha columna. Probar a entrenar la NN con los datos sin NA. Probar la parte de ir calculando el modelo para cada columna y en función del número de NA de cada fila. Idea de probar a entrenar el modelo con los datos sin NA, pero a la hora de realizar las predicciones como en las filas con varios NA vamos a tener que poner el valor medio ir reentrenando estos modelos sucesivamente con las nuevas predicciones para los otros valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#import tqdm\n",
    "import datetime\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import BayesianRidge, Ridge\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.45 s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Add, BatchNormalization, Dropout\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\guill\\\\Documents\\\\Kaggle\\\\Tabular_Playground_Series_Jun_2022'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_1_0</th>\n",
       "      <th>F_1_1</th>\n",
       "      <th>F_1_2</th>\n",
       "      <th>F_1_3</th>\n",
       "      <th>F_1_4</th>\n",
       "      <th>F_1_5</th>\n",
       "      <th>F_1_6</th>\n",
       "      <th>F_1_7</th>\n",
       "      <th>F_1_8</th>\n",
       "      <th>F_1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>F_4_5</th>\n",
       "      <th>F_4_6</th>\n",
       "      <th>F_4_7</th>\n",
       "      <th>F_4_8</th>\n",
       "      <th>F_4_9</th>\n",
       "      <th>F_4_10</th>\n",
       "      <th>F_4_11</th>\n",
       "      <th>F_4_12</th>\n",
       "      <th>F_4_13</th>\n",
       "      <th>F_4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.354591</td>\n",
       "      <td>-0.464038</td>\n",
       "      <td>2.304115</td>\n",
       "      <td>0.734486</td>\n",
       "      <td>1.696395</td>\n",
       "      <td>0.136285</td>\n",
       "      <td>-0.518344</td>\n",
       "      <td>0.502640</td>\n",
       "      <td>-1.852504</td>\n",
       "      <td>-0.500665</td>\n",
       "      <td>...</td>\n",
       "      <td>3.744152</td>\n",
       "      <td>0.794438</td>\n",
       "      <td>0.265185</td>\n",
       "      <td>-0.561809</td>\n",
       "      <td>0.196480</td>\n",
       "      <td>0.373434</td>\n",
       "      <td>6.206995</td>\n",
       "      <td>3.809505</td>\n",
       "      <td>1.236486</td>\n",
       "      <td>1.182055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.380940</td>\n",
       "      <td>-0.499626</td>\n",
       "      <td>-0.418548</td>\n",
       "      <td>1.911725</td>\n",
       "      <td>-0.826130</td>\n",
       "      <td>-1.715371</td>\n",
       "      <td>-0.577091</td>\n",
       "      <td>-1.041486</td>\n",
       "      <td>0.596067</td>\n",
       "      <td>-0.363425</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.895826</td>\n",
       "      <td>-0.738275</td>\n",
       "      <td>2.361818</td>\n",
       "      <td>-0.060753</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>-0.271882</td>\n",
       "      <td>5.232157</td>\n",
       "      <td>-4.218259</td>\n",
       "      <td>-2.724883</td>\n",
       "      <td>-0.063775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256023</td>\n",
       "      <td>-1.059874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345678</td>\n",
       "      <td>1.513814</td>\n",
       "      <td>1.243864</td>\n",
       "      <td>-0.509648</td>\n",
       "      <td>-0.800481</td>\n",
       "      <td>-0.115945</td>\n",
       "      <td>0.595777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.252834</td>\n",
       "      <td>0.472496</td>\n",
       "      <td>2.491386</td>\n",
       "      <td>0.353381</td>\n",
       "      <td>-0.260682</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.116457</td>\n",
       "      <td>-2.131747</td>\n",
       "      <td>3.661499</td>\n",
       "      <td>-0.131576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.728420</td>\n",
       "      <td>-2.432399</td>\n",
       "      <td>-2.453602</td>\n",
       "      <td>-0.020509</td>\n",
       "      <td>0.333397</td>\n",
       "      <td>0.086049</td>\n",
       "      <td>-1.787601</td>\n",
       "      <td>0.667011</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>-2.217847</td>\n",
       "      <td>...</td>\n",
       "      <td>2.004600</td>\n",
       "      <td>-4.664806</td>\n",
       "      <td>-0.847211</td>\n",
       "      <td>-0.264249</td>\n",
       "      <td>0.664334</td>\n",
       "      <td>-0.557868</td>\n",
       "      <td>8.499483</td>\n",
       "      <td>-4.738799</td>\n",
       "      <td>-3.054611</td>\n",
       "      <td>0.494152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590212</td>\n",
       "      <td>-0.066127</td>\n",
       "      <td>0.468009</td>\n",
       "      <td>-1.096038</td>\n",
       "      <td>0.119399</td>\n",
       "      <td>-1.809710</td>\n",
       "      <td>0.466358</td>\n",
       "      <td>-0.053196</td>\n",
       "      <td>-0.580320</td>\n",
       "      <td>-1.143500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976937</td>\n",
       "      <td>2.558883</td>\n",
       "      <td>3.377724</td>\n",
       "      <td>0.846891</td>\n",
       "      <td>0.696032</td>\n",
       "      <td>0.554121</td>\n",
       "      <td>-5.979714</td>\n",
       "      <td>-2.869631</td>\n",
       "      <td>3.733057</td>\n",
       "      <td>-0.722943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>-0.823740</td>\n",
       "      <td>0.285673</td>\n",
       "      <td>0.343307</td>\n",
       "      <td>-0.436747</td>\n",
       "      <td>1.700549</td>\n",
       "      <td>-1.069432</td>\n",
       "      <td>0.819698</td>\n",
       "      <td>-0.168457</td>\n",
       "      <td>-0.429074</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.799592</td>\n",
       "      <td>-0.301352</td>\n",
       "      <td>5.339675</td>\n",
       "      <td>-0.991529</td>\n",
       "      <td>1.279494</td>\n",
       "      <td>-0.841051</td>\n",
       "      <td>-2.276500</td>\n",
       "      <td>1.762961</td>\n",
       "      <td>5.324553</td>\n",
       "      <td>-0.228733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.769106</td>\n",
       "      <td>-0.387363</td>\n",
       "      <td>-1.227469</td>\n",
       "      <td>0.601183</td>\n",
       "      <td>0.351161</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>-0.530277</td>\n",
       "      <td>0.853452</td>\n",
       "      <td>0.608646</td>\n",
       "      <td>1.648023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909697</td>\n",
       "      <td>-1.299360</td>\n",
       "      <td>-0.071713</td>\n",
       "      <td>-0.162173</td>\n",
       "      <td>0.072501</td>\n",
       "      <td>-0.614687</td>\n",
       "      <td>-1.265524</td>\n",
       "      <td>0.190385</td>\n",
       "      <td>-0.344112</td>\n",
       "      <td>-0.346807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.147534</td>\n",
       "      <td>-0.715276</td>\n",
       "      <td>-0.465049</td>\n",
       "      <td>-1.988941</td>\n",
       "      <td>-1.594535</td>\n",
       "      <td>-1.044882</td>\n",
       "      <td>3.159455</td>\n",
       "      <td>-0.634108</td>\n",
       "      <td>0.890382</td>\n",
       "      <td>-1.212444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.891854</td>\n",
       "      <td>3.105002</td>\n",
       "      <td>-3.470520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096988</td>\n",
       "      <td>0.569255</td>\n",
       "      <td>3.609790</td>\n",
       "      <td>-0.584108</td>\n",
       "      <td>-1.492096</td>\n",
       "      <td>-0.997502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-1.709886</td>\n",
       "      <td>-0.813785</td>\n",
       "      <td>-1.866536</td>\n",
       "      <td>-0.179420</td>\n",
       "      <td>2.231478</td>\n",
       "      <td>1.460122</td>\n",
       "      <td>-0.220585</td>\n",
       "      <td>-0.118496</td>\n",
       "      <td>-0.140064</td>\n",
       "      <td>1.362596</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135003</td>\n",
       "      <td>-5.127360</td>\n",
       "      <td>-3.903728</td>\n",
       "      <td>-1.597023</td>\n",
       "      <td>0.893159</td>\n",
       "      <td>0.379434</td>\n",
       "      <td>0.846266</td>\n",
       "      <td>-1.085554</td>\n",
       "      <td>3.122423</td>\n",
       "      <td>0.004831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>-0.806380</td>\n",
       "      <td>-0.025251</td>\n",
       "      <td>-0.875477</td>\n",
       "      <td>0.802440</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>-1.030684</td>\n",
       "      <td>-0.209134</td>\n",
       "      <td>-0.341420</td>\n",
       "      <td>2.367991</td>\n",
       "      <td>0.314807</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079820</td>\n",
       "      <td>-1.098772</td>\n",
       "      <td>-1.428362</td>\n",
       "      <td>-1.255175</td>\n",
       "      <td>0.509799</td>\n",
       "      <td>0.711470</td>\n",
       "      <td>-2.448386</td>\n",
       "      <td>2.334131</td>\n",
       "      <td>5.425421</td>\n",
       "      <td>-0.828847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F_1_0     F_1_1     F_1_2     F_1_3     F_1_4     F_1_5     F_1_6  \\\n",
       "0      -0.354591 -0.464038  2.304115  0.734486  1.696395  0.136285 -0.518344   \n",
       "1       1.380940 -0.499626 -0.418548  1.911725 -0.826130 -1.715371 -0.577091   \n",
       "2       0.256023 -1.059874       NaN  0.345678  1.513814  1.243864 -0.509648   \n",
       "3      -0.728420 -2.432399 -2.453602 -0.020509  0.333397  0.086049 -1.787601   \n",
       "4       0.590212 -0.066127  0.468009 -1.096038  0.119399 -1.809710  0.466358   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995 -0.823740  0.285673  0.343307 -0.436747  1.700549 -1.069432  0.819698   \n",
       "999996 -0.769106 -0.387363 -1.227469  0.601183  0.351161  0.219475 -0.530277   \n",
       "999997  0.147534 -0.715276 -0.465049 -1.988941 -1.594535 -1.044882  3.159455   \n",
       "999998 -1.709886 -0.813785 -1.866536 -0.179420  2.231478  1.460122 -0.220585   \n",
       "999999 -0.806380 -0.025251 -0.875477  0.802440  0.889492 -1.030684 -0.209134   \n",
       "\n",
       "           F_1_7     F_1_8     F_1_9  ...     F_4_5     F_4_6     F_4_7  \\\n",
       "0       0.502640 -1.852504 -0.500665  ...  3.744152  0.794438  0.265185   \n",
       "1      -1.041486  0.596067 -0.363425  ... -2.895826 -0.738275  2.361818   \n",
       "2      -0.800481 -0.115945  0.595777  ...  2.252834  0.472496  2.491386   \n",
       "3       0.667011  0.761564 -2.217847  ...  2.004600 -4.664806 -0.847211   \n",
       "4      -0.053196 -0.580320 -1.143500  ...  0.976937  2.558883  3.377724   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "999995 -0.168457 -0.429074  0.844075  ...  1.799592 -0.301352  5.339675   \n",
       "999996  0.853452  0.608646  1.648023  ...  1.909697 -1.299360 -0.071713   \n",
       "999997 -0.634108  0.890382 -1.212444  ...  2.891854  3.105002 -3.470520   \n",
       "999998 -0.118496 -0.140064  1.362596  ... -1.135003 -5.127360 -3.903728   \n",
       "999999 -0.341420  2.367991  0.314807  ...  1.079820 -1.098772 -1.428362   \n",
       "\n",
       "           F_4_8     F_4_9    F_4_10    F_4_11    F_4_12    F_4_13    F_4_14  \n",
       "0      -0.561809  0.196480  0.373434  6.206995  3.809505  1.236486  1.182055  \n",
       "1      -0.060753  0.727249 -0.271882  5.232157 -4.218259 -2.724883 -0.063775  \n",
       "2       0.353381 -0.260682 -0.000833 -0.116457 -2.131747  3.661499 -0.131576  \n",
       "3      -0.264249  0.664334 -0.557868  8.499483 -4.738799 -3.054611  0.494152  \n",
       "4       0.846891  0.696032  0.554121 -5.979714 -2.869631  3.733057 -0.722943  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "999995 -0.991529  1.279494 -0.841051 -2.276500  1.762961  5.324553 -0.228733  \n",
       "999996 -0.162173  0.072501 -0.614687 -1.265524  0.190385 -0.344112 -0.346807  \n",
       "999997       NaN  0.096988  0.569255  3.609790 -0.584108 -1.492096 -0.997502  \n",
       "999998 -1.597023  0.893159  0.379434  0.846266 -1.085554  3.122423  0.004831  \n",
       "999999 -1.255175  0.509799  0.711470 -2.448386  2.334131  5.425421 -0.828847  \n",
       "\n",
       "[1000000 rows x 80 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data csv\n",
    "\n",
    "data = pd.read_csv('data.csv').drop(\"row_id\", axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row-col</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-F_1_14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-F_3_23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-F_3_24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-F_1_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-F_4_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999993-F_4_2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999994-F_3_10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999994-F_4_9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999997-F_3_14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999997-F_4_8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row-col  value\n",
       "0            0-F_1_14    0.0\n",
       "1            0-F_3_23    0.0\n",
       "2            1-F_3_24    0.0\n",
       "3             2-F_1_2    0.0\n",
       "4             2-F_4_2    0.0\n",
       "...               ...    ...\n",
       "999995   999993-F_4_2    0.0\n",
       "999996  999994-F_3_10    0.0\n",
       "999997   999994-F_4_9    0.0\n",
       "999998  999997-F_3_14    0.0\n",
       "999999   999997-F_4_8    0.0\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read submission csv\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read train and test data previously saved\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train_na = pd.read_csv('train_na.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_na = pd.read_csv('test_na.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into 4 df for each group of columns (1, 2, 3 & 4)\n",
    "\n",
    "features = list(data.columns)\n",
    "features_1, features_2, features_3, features_4 = [], [], [], []\n",
    "\n",
    "F_col = [[], [], [], [], []]\n",
    "for feature in features:\n",
    "    for i in [1, 2, 3, 4]:\n",
    "        if feature.split('_')[1] == str(i):\n",
    "            F_col[i].append(feature)\n",
    "\n",
    "## Original data\n",
    "\n",
    "data_col = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    data_col[i] = data[F_col[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m train_col \u001b[38;5;241m=\u001b[39m [[], [], [], [], []]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m---> 22\u001b[0m     train_col[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m[F_col[i]]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m## Train with NA data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m train_col_na \u001b[38;5;241m=\u001b[39m [[], [], [], [], []]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "## Split data into 4 df for each group of columns (1, 2, 3 & 4)\n",
    "\n",
    "features = list(data.columns)\n",
    "features_1, features_2, features_3, features_4 = [], [], [], []\n",
    "\n",
    "F_col = [[], [], [], [], []]\n",
    "for feature in features:\n",
    "    for i in [1, 2, 3, 4]:\n",
    "        if feature.split('_')[1] == str(i):\n",
    "            F_col[i].append(feature)\n",
    "\n",
    "## Original data\n",
    "\n",
    "data_col = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    data_col[i] = data[F_col[i]]\n",
    "\n",
    "## Train data\n",
    "\n",
    "train_col = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    train_col[i] = train[F_col[i]]\n",
    "\n",
    "## Train with NA data\n",
    "\n",
    "train_col_na = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    train_col_na[i] = train_na[F_col[i]]\n",
    "\n",
    "## Test data\n",
    "\n",
    "test_col = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    test_col[i] = test[F_col[i]]\n",
    "\n",
    "## Test with NA data\n",
    "\n",
    "test_col_na = [[], [], [], [], []]\n",
    "for i in [1, 2, 3, 4]:\n",
    "    test_col_na[i] = test_na[F_col[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Defining model parameters...\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS     = 32 # For Testing Purposes, Increase for Final Submission...\n",
    "VERBOSE    = 0 \n",
    "NUM_FOLDS  = 3  # For Testing Purposes, Increase for Final Submission..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def nn_model():\n",
    "    \n",
    "    '''\n",
    "    Function to define the Neuronal Network architecture...\n",
    "    '''\n",
    "    \n",
    "    L2 = 65e-6\n",
    "    activation_func = 'swish'\n",
    "    inputs = Input(shape = (len(features) - 1)) # Remove current feature that's imputed\n",
    "    \n",
    "    x = Dense(128, \n",
    "              #use_bias  = True, \n",
    "              kernel_regularizer = tf.keras.regularizers.l2(L2), \n",
    "              activation = activation_func)(inputs)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(64, \n",
    "          #use_bias  = True, \n",
    "          kernel_regularizer = tf.keras.regularizers.l2(L2), \n",
    "          activation = activation_func)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(32, \n",
    "              #use_bias  = True, \n",
    "              kernel_regularizer = tf.keras.regularizers.l2(L2), \n",
    "              activation = activation_func)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1 , \n",
    "              #use_bias  = True, \n",
    "              #kernel_regularizer = tf.keras.regularizers.l2(L2),\n",
    "              activation = 'linear')(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Network = [64,32,16,1] With 16 Epochs...  *\n",
    "# Test Two Network = [128,64,32,1] With 16 Epochs... **\n",
    "# Test Three Network = [128,64,32,1] With 32 Epochs... ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "# Defining model training function...\n",
    "def fit_model(X_train, y_train, X_val, y_val, X_test, run = 0):\n",
    "    '''\n",
    "    '''\n",
    "    lr_start = 0.01\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    epochs = EPOCHS    \n",
    "    lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, patience = 4, verbose = VERBOSE)\n",
    "    es = EarlyStopping(monitor = 'val_loss',patience = 12, verbose = 1, mode = 'min', restore_best_weights = True)\n",
    "    callbacks = [lr, es]\n",
    "    \n",
    "    model = nn_model()\n",
    "    optimizer_func = tf.keras.optimizers.Adam(learning_rate = lr_start)\n",
    "    loss_func = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    model.compile(optimizer = optimizer_func, loss = loss_func)\n",
    "    \n",
    "    X_val = scaler.transform(X_val)\n",
    "    validation_data = (X_val, y_val)\n",
    "    \n",
    "    history = model.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data = validation_data, \n",
    "                        epochs          = epochs,\n",
    "                        verbose         = VERBOSE,\n",
    "                        batch_size      = BATCH_SIZE,\n",
    "                        shuffle         = True,\n",
    "                        callbacks       = callbacks\n",
    "                       )\n",
    "    \n",
    "    history_list.append(history.history)\n",
    "    #print(f'Training Loss:{history_list[-1][\"loss\"][-1]:.5f}')\n",
    "    callbacks, es, lr, history = None, None, None, None\n",
    "    \n",
    "    \n",
    "    y_val_pred = model.predict(X_val, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "    score = mean_absolute_error(y_val, y_val_pred)\n",
    "    \n",
    "    #print(f'Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}'\n",
    "    #      f'| MSE: {score:.5f}')\n",
    "    \n",
    "    score_list.append(score)\n",
    "    \n",
    "    tst_data_scaled = scaler.transform(X_test)\n",
    "    tst_pred = model.predict(tst_data_scaled)\n",
    "    predictions.append(tst_pred)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data for NA per rows = 1\n",
    "\n",
    "data_train = test_col[4].copy()\n",
    "data_test = train_col_na[4].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Colunm Name :  F_4_0\n",
      "Processing Colunm Name :  F_4_1\n",
      "Processing Colunm Name :  F_4_2\n",
      "Processing Colunm Name :  F_4_3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Processing Colunm Name :  F_4_4\n",
      "Processing Colunm Name :  F_4_5\n",
      "Processing Colunm Name :  F_4_6\n",
      "Processing Colunm Name :  F_4_7\n",
      "Processing Colunm Name :  F_4_8\n",
      "Processing Colunm Name :  F_4_9\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Processing Colunm Name :  F_4_10\n",
      "Processing Colunm Name :  F_4_11\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Processing Colunm Name :  F_4_12\n",
      "Processing Colunm Name :  F_4_13\n",
      "Processing Colunm Name :  F_4_14\n",
      "CPU times: total: 33min 48s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## NN for NA per rows = 1\n",
    "\n",
    "# Create empty lists to store NN training metrics and predictions\n",
    "\n",
    "\n",
    "# Creates a loop, train in all -1 columns use -1 column as a target...\n",
    "features = data_test.columns.to_list()\n",
    "prediction_nn_1 = pd.DataFrame()\n",
    "\n",
    "models_nn = dict()\n",
    "\n",
    "for feat in features:\n",
    "    print('Processing Colunm Name : ', feat)\n",
    "    # Create empty lists to store NN training metrics and predictions\n",
    "    history_list = []\n",
    "    score_list   = []\n",
    "    predictions  = []\n",
    "    \n",
    "    if data_test[feat].isnull().any():\n",
    "        #print('Training Model For: ',feat)\n",
    "        \n",
    "        # Identify missing values...\n",
    "        missing_values = list(np.where(data_test[feat].isnull())[0])\n",
    "\n",
    "        trn_data = data_train\n",
    "        tst_data = data_test.iloc[missing_values,]\n",
    "        \n",
    "        # Define kfolds for training purposes...\n",
    "        kf = KFold(n_splits = NUM_FOLDS)\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kf.split(trn_data)):\n",
    "            #print(f' Training fold: {fold}...')\n",
    "            X_train, X_val = trn_data.iloc[trn_idx].drop([feat],axis = 1), trn_data.iloc[val_idx].drop([feat], axis = 1)\n",
    "            y_train, y_val = trn_data.iloc[trn_idx][feat], trn_data.iloc[val_idx][feat]\n",
    "            X_test = tst_data.drop([feat], axis = 1)\n",
    "            \n",
    "            X_train, X_val = X_train.fillna(X_train.mean()), X_val.fillna(X_val.mean())\n",
    "            X_test = X_test.fillna(X_test.mean())\n",
    "            \n",
    "            fit_model(X_train, y_train, X_val, y_val, X_test)\n",
    "        \n",
    "        mean_values = np.array(predictions).mean(axis = 0)\n",
    "        imputed_data = data_test[feat]\n",
    "        imputed_data.iloc[missing_values] = mean_values.ravel()\n",
    "        prediction_nn_1 = pd.concat([prediction_nn_1, imputed_data],axis = 1)\n",
    "    \n",
    "    else:\n",
    "        prediction_nn_1 = pd.concat([prediction_nn_1, data_test[feat]],axis = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272528"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col[4].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_col_no_na = data_col[4][(data_col[4].isna().sum(axis=1) == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data for NA per rows > 1\n",
    "\n",
    "data_train = data_col[4].copy()\n",
    "data_test = data_col[4].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Colunm Name :  F_4_0\n",
      "567/567 [==============================] - 0s 578us/step\n",
      "567/567 [==============================] - 0s 585us/step\n",
      "567/567 [==============================] - 0s 613us/step\n",
      "Processing Colunm Name :  F_4_1\n",
      "568/568 [==============================] - 0s 592us/step\n",
      "568/568 [==============================] - 0s 643us/step\n",
      "568/568 [==============================] - 0s 657us/step\n",
      "Processing Colunm Name :  F_4_2\n",
      "578/578 [==============================] - 0s 628us/step\n",
      "578/578 [==============================] - 0s 615us/step\n",
      "578/578 [==============================] - 0s 602us/step\n",
      "Processing Colunm Name :  F_4_3\n",
      "564/564 [==============================] - 0s 611us/step\n",
      "564/564 [==============================] - 0s 637us/step\n",
      "564/564 [==============================] - 0s 624us/step\n",
      "Processing Colunm Name :  F_4_4\n",
      "562/562 [==============================] - 0s 647us/step\n",
      "562/562 [==============================] - 0s 608us/step\n",
      "562/562 [==============================] - 0s 628us/step\n",
      "Processing Colunm Name :  F_4_5\n",
      "565/565 [==============================] - 0s 637us/step\n",
      "565/565 [==============================] - 0s 626us/step\n",
      "565/565 [==============================] - 0s 645us/step\n",
      "Processing Colunm Name :  F_4_6\n",
      "573/573 [==============================] - 0s 627us/step\n",
      "573/573 [==============================] - 0s 645us/step\n",
      "573/573 [==============================] - 0s 637us/step\n",
      "Processing Colunm Name :  F_4_7\n",
      "563/563 [==============================] - 0s 597us/step\n",
      "563/563 [==============================] - 0s 604us/step\n",
      "563/563 [==============================] - 0s 623us/step\n",
      "Processing Colunm Name :  F_4_8\n",
      "568/568 [==============================] - 0s 705us/step\n",
      "568/568 [==============================] - 0s 695us/step\n",
      "568/568 [==============================] - 0s 695us/step\n",
      "Processing Colunm Name :  F_4_9\n",
      "571/571 [==============================] - 0s 630us/step\n",
      "571/571 [==============================] - 0s 646us/step\n",
      "571/571 [==============================] - 0s 638us/step\n",
      "Processing Colunm Name :  F_4_10\n",
      "570/570 [==============================] - 0s 639us/step\n",
      "570/570 [==============================] - 0s 634us/step\n",
      "570/570 [==============================] - 0s 604us/step\n",
      "Processing Colunm Name :  F_4_11\n",
      "567/567 [==============================] - 0s 645us/step\n",
      "567/567 [==============================] - 0s 643us/step\n",
      "567/567 [==============================] - 0s 621us/step\n",
      "Processing Colunm Name :  F_4_12\n",
      "573/573 [==============================] - 0s 629us/step\n",
      "573/573 [==============================] - 0s 644us/step\n",
      "573/573 [==============================] - 0s 635us/step\n",
      "Processing Colunm Name :  F_4_13\n",
      "563/563 [==============================] - 0s 623us/step\n",
      "563/563 [==============================] - 0s 629us/step\n",
      "563/563 [==============================] - 0s 600us/step\n",
      "Processing Colunm Name :  F_4_14\n",
      "571/571 [==============================] - 0s 634us/step\n",
      "571/571 [==============================] - 0s 604us/step\n",
      "571/571 [==============================] - 0s 602us/step\n",
      "CPU times: total: 5h 59min 23s\n",
      "Wall time: 4h 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## NN for NA per row > 1\n",
    "\n",
    "# Create empty lists to store NN training metrics and predictions\n",
    "\n",
    "# Creates a loop, train in all -1 columns use -1 column as a target...\n",
    "features = data_test.columns.to_list()\n",
    "prediction_nn_1 = pd.DataFrame()\n",
    "\n",
    "models_nn = dict()\n",
    "\n",
    "for feat in features:\n",
    "    print('Processing Colunm Name : ', feat)\n",
    "    # Create empty lists to store NN training metrics and predictions\n",
    "    history_list = []\n",
    "    score_list   = []\n",
    "    predictions  = []\n",
    "    \n",
    "    if data_test[feat].isnull().any():\n",
    "        #print('Training Model For: ',feat)\n",
    "        \n",
    "        # Identify missing values...\n",
    "        not_missing_values_train = list(np.where(data_train[feat].isnull() == False)[0])\n",
    "        missing_values_test = list(np.where(data_test[feat].isnull())[0])\n",
    "\n",
    "        trn_data = data_train.iloc[not_missing_values_train,]\n",
    "        tst_data = data_test.iloc[missing_values_test,]\n",
    "        \n",
    "        # Define kfolds for training purposes...\n",
    "        kf = KFold(n_splits = NUM_FOLDS)\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kf.split(trn_data)):\n",
    "            #print(f' Training fold: {fold}...')\n",
    "            X_train, X_val = trn_data.iloc[trn_idx].drop([feat],axis = 1), trn_data.iloc[val_idx].drop([feat], axis = 1)\n",
    "            y_train, y_val = trn_data.iloc[trn_idx][feat], trn_data.iloc[val_idx][feat]\n",
    "            X_test = tst_data.drop([feat], axis = 1)\n",
    "            \n",
    "            X_train, X_val = X_train.fillna(X_train.mean()), X_val.fillna(X_val.mean())\n",
    "            X_test = X_test.fillna(X_test.mean())\n",
    "            \n",
    "            models_nn[feat] = fit_model(X_train, y_train, X_val, y_val, X_test)\n",
    "        \n",
    "        mean_values = np.array(predictions).mean(axis = 0)\n",
    "        imputed_data = data_test[feat]\n",
    "        imputed_data.iloc[missing_values_test] = mean_values.ravel()\n",
    "        prediction_nn_1 = pd.concat([prediction_nn_1, imputed_data],axis = 1)\n",
    "    \n",
    "    else:\n",
    "        prediction_nn_1 = pd.concat([prediction_nn_1, data_test[feat]],axis = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Colunm Name :  F_4_0\n",
      "RMSE for Test of this column :  0.6656534696357426\n",
      "Processing Colunm Name :  F_4_1\n",
      "RMSE for Test of this column :  0.4763748400744299\n",
      "Processing Colunm Name :  F_4_2\n",
      "RMSE for Test of this column :  0.14762706014720212\n",
      "Processing Colunm Name :  F_4_3\n",
      "RMSE for Test of this column :  0.26124079795993815\n",
      "Processing Colunm Name :  F_4_4\n",
      "RMSE for Test of this column :  0.3314777939304229\n",
      "Processing Colunm Name :  F_4_5\n",
      "RMSE for Test of this column :  0.3686191190617441\n",
      "Processing Colunm Name :  F_4_6\n",
      "RMSE for Test of this column :  0.7560190890448347\n",
      "Processing Colunm Name :  F_4_7\n",
      "RMSE for Test of this column :  0.48834705552653807\n",
      "Processing Colunm Name :  F_4_8\n",
      "RMSE for Test of this column :  0.09493132543460063\n",
      "Processing Colunm Name :  F_4_9\n",
      "RMSE for Test of this column :  0.2578091199760006\n",
      "Processing Colunm Name :  F_4_10\n",
      "RMSE for Test of this column :  0.13213389090259983\n",
      "Processing Colunm Name :  F_4_11\n",
      "RMSE for Test of this column :  0.3298681498044601\n",
      "Processing Colunm Name :  F_4_12\n",
      "RMSE for Test of this column :  0.420550786895402\n",
      "Processing Colunm Name :  F_4_13\n",
      "RMSE for Test of this column :  0.2975447863604796\n",
      "Processing Colunm Name :  F_4_14\n",
      "RMSE for Test of this column :  0.10634025940538584\n",
      "CPU times: total: 12h 8min 14s\n",
      "Wall time: 1h 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## LGBM Regressor\n",
    "\n",
    "for i in [4]:\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    test_predictions_1 = pd.DataFrame()\n",
    "    test_predictions_2 = pd.DataFrame()\n",
    "    test_predictions_3 = pd.DataFrame()\n",
    "    test_predictions_4 = pd.DataFrame()\n",
    "    test_predictions_5 = pd.DataFrame()\n",
    "    col_test_train = pd.DataFrame()\n",
    "    col_test_test = pd.DataFrame()\n",
    "    train_df = data_col[i].copy()\n",
    "    test_df = data_col[i].copy()\n",
    "    test_predictions_1 = data_col[i].copy()\n",
    "    test_predictions_2 = data_col[i].copy()\n",
    "    test_predictions_3 = data_col[i].copy()\n",
    "    test_predictions_4 = data_col[i].copy()\n",
    "    test_predictions_5 = data_col[i].copy()\n",
    "\n",
    "    models_lgbm = dict()\n",
    "\n",
    "    for column in data_col[i].columns:\n",
    "        print('Processing Colunm Name : ', column)\n",
    "        col_nan_ix_test = test_df[test_df[column].isnull()].index  # identify the rows which has NaN in column F_4_0\n",
    "        col_nan_ix_train = train_df[train_df[column].isnull()].index  # identify the rows which has NaN in column F_4_0\n",
    "\n",
    "        col_test_train = train_df.drop(col_nan_ix_train, axis = 0) \n",
    "        col_test_test = test_df[test_df.index.isin(col_nan_ix_test)] \n",
    "\n",
    "        X_test = col_test_train.drop([column],axis=1)\n",
    "        y_test = col_test_train[column]\n",
    "\n",
    "        models_lgbm[column] = LGBMRegressor(n_estimators = 10000)\n",
    "        models_lgbm[column].fit(X_test,y_test)\n",
    "\n",
    "        rmse_test = mean_squared_error(y_test, models_lgbm[column].predict(X_test), squared = False)\n",
    "        print('RMSE for Test of this column : ', rmse_test)\n",
    "\n",
    "        test_predictions_1[column][col_nan_ix_test] = models_lgbm[column].predict(col_test_test.drop([column],axis=1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Colunm Name :  F_4_0\n",
      "567/567 [==============================] - 0s 629us/step\n",
      "Processing Colunm Name :  F_4_1\n",
      "568/568 [==============================] - 0s 680us/step\n",
      "Processing Colunm Name :  F_4_2\n",
      "578/578 [==============================] - 0s 642us/step\n",
      "Processing Colunm Name :  F_4_3\n",
      "564/564 [==============================] - 0s 632us/step\n",
      "Processing Colunm Name :  F_4_4\n",
      "562/562 [==============================] - 0s 633us/step\n",
      "Processing Colunm Name :  F_4_5\n",
      "565/565 [==============================] - 0s 608us/step\n",
      "Processing Colunm Name :  F_4_6\n",
      "573/573 [==============================] - 0s 617us/step\n",
      "Processing Colunm Name :  F_4_7\n",
      "563/563 [==============================] - 0s 621us/step\n",
      "Processing Colunm Name :  F_4_8\n",
      "568/568 [==============================] - 0s 689us/step\n",
      "Processing Colunm Name :  F_4_9\n",
      "571/571 [==============================] - 0s 638us/step\n",
      "Processing Colunm Name :  F_4_10\n",
      "570/570 [==============================] - 0s 630us/step\n",
      "Processing Colunm Name :  F_4_11\n",
      "567/567 [==============================] - 0s 589us/step\n",
      "Processing Colunm Name :  F_4_12\n",
      "573/573 [==============================] - 0s 603us/step\n",
      "Processing Colunm Name :  F_4_13\n",
      "563/563 [==============================] - 0s 666us/step\n",
      "Processing Colunm Name :  F_4_14\n",
      "571/571 [==============================] - 0s 625us/step\n",
      "CPU times: total: 18.1 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## NN for NA per row > 1\n",
    "\n",
    "# Create empty lists to store NN training metrics and predictions\n",
    "\n",
    "data_test = data_col[4].copy()\n",
    "\n",
    "# Creates a loop, train in all -1 columns use -1 column as a target...\n",
    "features = data_test.columns.to_list()\n",
    "\n",
    "#prediction_nn_2 = pd.DataFrame()\n",
    "prediction_nn_3 = pd.DataFrame()\n",
    "#prediction_nn_4 = pd.DataFrame()\n",
    "#prediction_nn_5 = pd.DataFrame()\n",
    "\n",
    "for feat in features:\n",
    "    print('Processing Colunm Name : ', feat)\n",
    "    # Create empty lists to store NN training metrics and predictions\n",
    "    history_list = []\n",
    "    score_list   = []\n",
    "    predictions  = []\n",
    "    \n",
    "    if data_test[feat].isnull().any():\n",
    "        #print('Training Model For: ',feat)\n",
    "        \n",
    "        # Identify missing values...\n",
    "        missing_values_test = list(np.where(data_test[feat].isnull())[0])\n",
    "        not_missing_values_train = list(np.where(data_train[feat].isnull() == False)[0])\n",
    "\n",
    "        trn_data = data_train.iloc[not_missing_values_train,]\n",
    "        tst_data = prediction_nn_1.iloc[missing_values_test,]\n",
    "\n",
    "        X_train = trn_data.drop([feat], axis = 1)\n",
    "        X_test = tst_data.drop([feat], axis = 1)\n",
    "\n",
    "        model = models_nn[feat]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        tst_data_scaled = scaler.transform(X_test)\n",
    "        tst_pred = model.predict(tst_data_scaled)\n",
    "        predictions.append(tst_pred)\n",
    "        \n",
    "        mean_values = np.array(predictions).mean(axis = 0)\n",
    "        imputed_data = prediction_nn_1[feat]\n",
    "        imputed_data.iloc[missing_values_test] = mean_values.ravel()\n",
    "        prediction_nn_3 = pd.concat([prediction_nn_3, imputed_data],axis = 1)\n",
    "    \n",
    "    else:\n",
    "        prediction_nn_3 = pd.concat([prediction_nn_3, prediction_nn_1[feat]],axis = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions nº 2\n",
      "Processing Colunm Name :  F_4_0\n",
      "Processing Colunm Name :  F_4_1\n",
      "Processing Colunm Name :  F_4_2\n",
      "Processing Colunm Name :  F_4_3\n",
      "Processing Colunm Name :  F_4_4\n",
      "Processing Colunm Name :  F_4_5\n",
      "Processing Colunm Name :  F_4_6\n",
      "Processing Colunm Name :  F_4_7\n",
      "Processing Colunm Name :  F_4_8\n",
      "Processing Colunm Name :  F_4_9\n",
      "Processing Colunm Name :  F_4_10\n",
      "Processing Colunm Name :  F_4_11\n",
      "Processing Colunm Name :  F_4_12\n",
      "Processing Colunm Name :  F_4_13\n",
      "Processing Colunm Name :  F_4_14\n",
      "Predictions nº 3\n",
      "Processing Colunm Name :  F_4_0\n",
      "Processing Colunm Name :  F_4_1\n",
      "Processing Colunm Name :  F_4_2\n",
      "Processing Colunm Name :  F_4_3\n",
      "Processing Colunm Name :  F_4_4\n",
      "Processing Colunm Name :  F_4_5\n",
      "Processing Colunm Name :  F_4_6\n",
      "Processing Colunm Name :  F_4_7\n",
      "Processing Colunm Name :  F_4_8\n",
      "Processing Colunm Name :  F_4_9\n",
      "Processing Colunm Name :  F_4_10\n",
      "Processing Colunm Name :  F_4_11\n",
      "Processing Colunm Name :  F_4_12\n",
      "Processing Colunm Name :  F_4_13\n",
      "Processing Colunm Name :  F_4_14\n",
      "Predictions nº 4\n",
      "Processing Colunm Name :  F_4_0\n",
      "Processing Colunm Name :  F_4_1\n",
      "Processing Colunm Name :  F_4_2\n",
      "Processing Colunm Name :  F_4_3\n",
      "Processing Colunm Name :  F_4_4\n",
      "Processing Colunm Name :  F_4_5\n",
      "Processing Colunm Name :  F_4_6\n",
      "Processing Colunm Name :  F_4_7\n",
      "Processing Colunm Name :  F_4_8\n",
      "Processing Colunm Name :  F_4_9\n",
      "Processing Colunm Name :  F_4_10\n",
      "Processing Colunm Name :  F_4_11\n",
      "Processing Colunm Name :  F_4_12\n",
      "Processing Colunm Name :  F_4_13\n",
      "Processing Colunm Name :  F_4_14\n",
      "Predictions nº 5\n",
      "Processing Colunm Name :  F_4_0\n",
      "Processing Colunm Name :  F_4_1\n",
      "Processing Colunm Name :  F_4_2\n",
      "Processing Colunm Name :  F_4_3\n",
      "Processing Colunm Name :  F_4_4\n",
      "Processing Colunm Name :  F_4_5\n",
      "Processing Colunm Name :  F_4_6\n",
      "Processing Colunm Name :  F_4_7\n",
      "Processing Colunm Name :  F_4_8\n",
      "Processing Colunm Name :  F_4_9\n",
      "Processing Colunm Name :  F_4_10\n",
      "Processing Colunm Name :  F_4_11\n",
      "Processing Colunm Name :  F_4_12\n",
      "Processing Colunm Name :  F_4_13\n",
      "Processing Colunm Name :  F_4_14\n"
     ]
    }
   ],
   "source": [
    "## Create 5 new prediction using the previous prediction data\n",
    "\n",
    "for i in range(1, 5):\n",
    "    print('Predictions nº', i + 1)\n",
    "    for column in data_col[4].columns:\n",
    "        print('Processing Colunm Name : ', column)\n",
    "        col_nan_ix_test = test_df[test_df[column].isnull()].index  # identify the rows which has NaN in column F_4_0\n",
    "        locals()['test_predictions_{0}'.format(i+1)][column][col_nan_ix_test] = models_lgbm[column].predict(locals()['test_predictions_{0}'.format(i)][test_df.index.isin(col_nan_ix_test)].drop([column],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_106896\\94324379.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_col_na[1][:] = imp.fit_transform(train_col_na[1])\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_106896\\94324379.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_col_na[1][:] = imp.fit_transform(train_col_na[1])\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_106896\\94324379.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_col_na[3][:] = imp.fit_transform(train_col_na[3])\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_106896\\94324379.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_col_na[3][:] = imp.fit_transform(train_col_na[3])\n"
     ]
    }
   ],
   "source": [
    "## Simple Imputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_col_na[1][:] = imp.fit_transform(train_col_na[1])\n",
    "train_col_na[3][:] = imp.fit_transform(train_col_na[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col_na[3].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_4_0</th>\n",
       "      <th>F_4_1</th>\n",
       "      <th>F_4_2</th>\n",
       "      <th>F_4_3</th>\n",
       "      <th>F_4_4</th>\n",
       "      <th>F_4_5</th>\n",
       "      <th>F_4_6</th>\n",
       "      <th>F_4_7</th>\n",
       "      <th>F_4_8</th>\n",
       "      <th>F_4_9</th>\n",
       "      <th>F_4_10</th>\n",
       "      <th>F_4_11</th>\n",
       "      <th>F_4_12</th>\n",
       "      <th>F_4_13</th>\n",
       "      <th>F_4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.795409</td>\n",
       "      <td>-0.623789</td>\n",
       "      <td>-0.770260</td>\n",
       "      <td>-0.440950</td>\n",
       "      <td>0.215060</td>\n",
       "      <td>1.719414</td>\n",
       "      <td>1.441969</td>\n",
       "      <td>1.595714</td>\n",
       "      <td>-0.815760</td>\n",
       "      <td>-0.488741</td>\n",
       "      <td>-1.071421</td>\n",
       "      <td>4.214355</td>\n",
       "      <td>-4.727274</td>\n",
       "      <td>1.104052</td>\n",
       "      <td>-0.108112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>-3.389891</td>\n",
       "      <td>-2.247449</td>\n",
       "      <td>0.568458</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>4.401177</td>\n",
       "      <td>2.675807</td>\n",
       "      <td>2.983970</td>\n",
       "      <td>0.293305</td>\n",
       "      <td>0.015338</td>\n",
       "      <td>-0.594958</td>\n",
       "      <td>-0.262718</td>\n",
       "      <td>0.863743</td>\n",
       "      <td>1.335779</td>\n",
       "      <td>-1.277215</td>\n",
       "      <td>-0.444087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>-0.354968</td>\n",
       "      <td>-0.127725</td>\n",
       "      <td>0.092135</td>\n",
       "      <td>-0.325934</td>\n",
       "      <td>-0.849824</td>\n",
       "      <td>-0.967033</td>\n",
       "      <td>-2.641119</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>-0.305581</td>\n",
       "      <td>0.128901</td>\n",
       "      <td>-1.094825</td>\n",
       "      <td>-3.912872</td>\n",
       "      <td>1.299774</td>\n",
       "      <td>0.277912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>1.981048</td>\n",
       "      <td>-3.418477</td>\n",
       "      <td>0.507936</td>\n",
       "      <td>-0.462010</td>\n",
       "      <td>0.065459</td>\n",
       "      <td>2.479947</td>\n",
       "      <td>-0.774990</td>\n",
       "      <td>2.533314</td>\n",
       "      <td>-1.117679</td>\n",
       "      <td>0.715366</td>\n",
       "      <td>0.636271</td>\n",
       "      <td>3.128637</td>\n",
       "      <td>1.333375</td>\n",
       "      <td>0.991761</td>\n",
       "      <td>-0.257106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>0.274585</td>\n",
       "      <td>-3.043946</td>\n",
       "      <td>-0.518985</td>\n",
       "      <td>0.330013</td>\n",
       "      <td>-0.180993</td>\n",
       "      <td>-1.654114</td>\n",
       "      <td>-1.916158</td>\n",
       "      <td>3.379293</td>\n",
       "      <td>0.176179</td>\n",
       "      <td>-0.541852</td>\n",
       "      <td>-0.339082</td>\n",
       "      <td>-2.961478</td>\n",
       "      <td>0.823927</td>\n",
       "      <td>1.599802</td>\n",
       "      <td>0.011015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995228</th>\n",
       "      <td>-0.049236</td>\n",
       "      <td>-2.852658</td>\n",
       "      <td>0.838019</td>\n",
       "      <td>0.554093</td>\n",
       "      <td>-4.211202</td>\n",
       "      <td>-4.276435</td>\n",
       "      <td>-0.805499</td>\n",
       "      <td>-1.343661</td>\n",
       "      <td>0.024478</td>\n",
       "      <td>0.853383</td>\n",
       "      <td>0.927234</td>\n",
       "      <td>-6.708188</td>\n",
       "      <td>4.327698</td>\n",
       "      <td>-0.526517</td>\n",
       "      <td>0.795305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996495</th>\n",
       "      <td>1.377608</td>\n",
       "      <td>2.395085</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>1.101640</td>\n",
       "      <td>3.327307</td>\n",
       "      <td>0.312895</td>\n",
       "      <td>4.060688</td>\n",
       "      <td>1.025454</td>\n",
       "      <td>-1.329940</td>\n",
       "      <td>0.201551</td>\n",
       "      <td>1.379496</td>\n",
       "      <td>-2.031798</td>\n",
       "      <td>1.698120</td>\n",
       "      <td>0.423992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997355</th>\n",
       "      <td>-0.979589</td>\n",
       "      <td>-1.151294</td>\n",
       "      <td>-1.952817</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>-2.259924</td>\n",
       "      <td>0.436069</td>\n",
       "      <td>0.164168</td>\n",
       "      <td>2.822745</td>\n",
       "      <td>-0.028007</td>\n",
       "      <td>0.668826</td>\n",
       "      <td>-0.054950</td>\n",
       "      <td>0.928307</td>\n",
       "      <td>2.897985</td>\n",
       "      <td>-0.304072</td>\n",
       "      <td>0.074433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997382</th>\n",
       "      <td>2.202326</td>\n",
       "      <td>-1.605612</td>\n",
       "      <td>-0.401132</td>\n",
       "      <td>-0.159647</td>\n",
       "      <td>1.026073</td>\n",
       "      <td>-0.046044</td>\n",
       "      <td>2.773899</td>\n",
       "      <td>1.350840</td>\n",
       "      <td>-1.199721</td>\n",
       "      <td>0.695865</td>\n",
       "      <td>-0.080005</td>\n",
       "      <td>2.004351</td>\n",
       "      <td>-0.034295</td>\n",
       "      <td>0.398658</td>\n",
       "      <td>-0.973724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999154</th>\n",
       "      <td>-0.348458</td>\n",
       "      <td>-2.529795</td>\n",
       "      <td>-0.709129</td>\n",
       "      <td>-0.887021</td>\n",
       "      <td>2.663267</td>\n",
       "      <td>-1.694709</td>\n",
       "      <td>-4.594006</td>\n",
       "      <td>-1.982417</td>\n",
       "      <td>-0.613531</td>\n",
       "      <td>-0.055427</td>\n",
       "      <td>-0.942628</td>\n",
       "      <td>11.584227</td>\n",
       "      <td>-2.732451</td>\n",
       "      <td>-6.038339</td>\n",
       "      <td>1.315489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F_4_0     F_4_1     F_4_2     F_4_3     F_4_4     F_4_5     F_4_6  \\\n",
       "1916    0.795409 -0.623789 -0.770260 -0.440950  0.215060  1.719414  1.441969   \n",
       "2137   -3.389891 -2.247449  0.568458 -0.009249  4.401177  2.675807  2.983970   \n",
       "2215   -0.354968 -0.127725  0.092135 -0.325934 -0.849824 -0.967033 -2.641119   \n",
       "2396    1.981048 -3.418477  0.507936 -0.462010  0.065459  2.479947 -0.774990   \n",
       "3080    0.274585 -3.043946 -0.518985  0.330013 -0.180993 -1.654114 -1.916158   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "995228 -0.049236 -2.852658  0.838019  0.554093 -4.211202 -4.276435 -0.805499   \n",
       "996495  1.377608  2.395085  0.252500  0.027860  1.101640  3.327307  0.312895   \n",
       "997355 -0.979589 -1.151294 -1.952817  0.145374 -2.259924  0.436069  0.164168   \n",
       "997382  2.202326 -1.605612 -0.401132 -0.159647  1.026073 -0.046044  2.773899   \n",
       "999154 -0.348458 -2.529795 -0.709129 -0.887021  2.663267 -1.694709 -4.594006   \n",
       "\n",
       "           F_4_7     F_4_8     F_4_9    F_4_10     F_4_11    F_4_12    F_4_13  \\\n",
       "1916    1.595714 -0.815760 -0.488741 -1.071421   4.214355 -4.727274  1.104052   \n",
       "2137    0.293305  0.015338 -0.594958 -0.262718   0.863743  1.335779 -1.277215   \n",
       "2215   -0.740895  0.393292 -0.305581  0.128901  -1.094825 -3.912872  1.299774   \n",
       "2396    2.533314 -1.117679  0.715366  0.636271   3.128637  1.333375  0.991761   \n",
       "3080    3.379293  0.176179 -0.541852 -0.339082  -2.961478  0.823927  1.599802   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "995228 -1.343661  0.024478  0.853383  0.927234  -6.708188  4.327698 -0.526517   \n",
       "996495  4.060688  1.025454 -1.329940  0.201551   1.379496 -2.031798  1.698120   \n",
       "997355  2.822745 -0.028007  0.668826 -0.054950   0.928307  2.897985 -0.304072   \n",
       "997382  1.350840 -1.199721  0.695865 -0.080005   2.004351 -0.034295  0.398658   \n",
       "999154 -1.982417 -0.613531 -0.055427 -0.942628  11.584227 -2.732451 -6.038339   \n",
       "\n",
       "          F_4_14  \n",
       "1916   -0.108112  \n",
       "2137   -0.444087  \n",
       "2215    0.277912  \n",
       "2396   -0.257106  \n",
       "3080    0.011015  \n",
       "...          ...  \n",
       "995228  0.795305  \n",
       "996495  0.423992  \n",
       "997355  0.074433  \n",
       "997382 -0.973724  \n",
       "999154  1.315489  \n",
       "\n",
       "[2124 rows x 15 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4_na_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([train_col_na[1], train_col_na[2], train_col_na[3], data_completed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_col_na[4][train_col_na[4].isna().sum(axis=1) == 1] = test_predictions_1[train_col_na[4].isna().sum(axis=1) == 1]\n",
    "test_4_na_1 = prediction_nn_1[data_col[4].isna().sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_col_na[4][train_col_na[4].isna().sum(axis=1) == 2] = test_predictions_3[train_col_na[4].isna().sum(axis=1) == 2]\n",
    "test_4_na_2 = test_predictions_3[data_col[4].isna().sum(axis=1) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_col_na[4][train_col_na[4].isna().sum(axis=1) == 3] = test_predictions_1[train_col_na[4].isna().sum(axis=1) == 3]\n",
    "test_4_na_3 = prediction_nn_2[data_col[4].isna().sum(axis=1) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_col_na[4][train_col_na[4].isna().sum(axis=1) == 4] = test_predictions_1[train_col_na[4].isna().sum(axis=1) == 4]\n",
    "test_4_na_4 = prediction_nn_3[data_col[4].isna().sum(axis=1) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_col_na[4][train_col_na[4].isna().sum(axis=1) == 4] = test_predictions_1[train_col_na[4].isna().sum(axis=1) == 4]\n",
    "test_4_na_5 = prediction_nn_3[data_col[4].isna().sum(axis=1) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_1 = train_col[4][train_col_na[4].isna().sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_2 = train_col[4][train_col_na[4].isna().sum(axis=1) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_3 = train_col[4][train_col_na[4].isna().sum(axis=1) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_4 = train_col[4][train_col_na[4].isna().sum(axis=1) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_na_1_2_3_4 = pd.concat([test_4_na_1, test_4_na_2, test_4_na_3, test_4_na_4],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4_1_2_3_4 = pd.concat([test_4_1, test_4_2, test_4_3, test_4_4],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2800208716692978"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RMSE Cols DF Test (15000/25000) Train (60000/100000) \n",
    "\n",
    "error_df_br = prediction_nn_4.sub(train_col[4])\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 60000\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607246801622356"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RMSE Cols DF Test NA Count (11675, 2972, 333, 20 / 13277) Train NA Count (46674, 11836, 1374, 116 / 53079) \n",
    "\n",
    "error_df_br = test_4_na_2.sub(test_4_2)\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 11836\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([train_col_na[1], train_col_na[2], train_col_na[3], prediction_nn_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0949812403095471"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RMSE DF Test (55000) Train (220000)\n",
    "\n",
    "error_df_br = data_concat.sub(train)\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 220000\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count of NA per row\n",
    "\n",
    "na_cnt = pd.DataFrame(data_col[4].isna().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0     999996\n",
       "15         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cnt.groupby([0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NA = 1 -> NN with No NA (1 iter)\n",
    "## NA = 2 -> LGBM with NA (3)\n",
    "## NA = 3 -> NN with NA (2)\n",
    "## NA = 4 -> NN with NA (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_na_1 = test_4_na_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_4_na_2 = test_4_na_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_4_na_3 = test_4_na_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_4_na_4 = test_4_na_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col[4].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 1] = test_4_na_1\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 1] = test_4_na_1\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 2] = test_4_na_2\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 2] = test_4_na_2\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 3] = test_4_na_3\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 3] = test_4_na_3\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 4] = test_4_na_4\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 4] = test_4_na_4\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 5] = test_4_na_5\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\3842458909.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 5] = test_4_na_5\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 1] = test_4_na_1\n",
    "data_col[4][data_col[4].isna().sum(axis=1) == 2] = test_4_na_2\n",
    "data_col[4][data_col[4].isna().sum(axis=1) == 3] = test_4_na_3\n",
    "data_col[4][data_col[4].isna().sum(axis=1) == 4] = test_4_na_4\n",
    "data_col[4][data_col[4].isna().sum(axis=1) == 5] = test_4_na_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\2674904411.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[1][:] = imp.fit_transform(data_col[1])\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\2674904411.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[1][:] = imp.fit_transform(data_col[1])\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\2674904411.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[3][:] = imp.fit_transform(data_col[3])\n",
      "C:\\Users\\guill\\AppData\\Local\\Temp\\ipykernel_29252\\2674904411.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[3][:] = imp.fit_transform(data_col[3])\n"
     ]
    }
   ],
   "source": [
    "## Simple Imputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data_col[1][:] = imp.fit_transform(data_col[1])\n",
    "data_col[3][:] = imp.fit_transform(data_col[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([data_col[1], data_col[2], data_col[3], data_col[4]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5412321992730276"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RMSE Cols DF Test (15000/25000) Train (60000/100000) \n",
    "\n",
    "error_df_br = train_col_na[4].sub(train_col[4])\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 60000\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607246801622356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## RMSE Cols DF Test NA Count (11675, 2972, 333, 20 / 13277) Train NA Count (46674, 11836, 1374, 116 / 53079) \n",
    "\n",
    "error_df_br = test_4_na_2.sub(test_4_2)\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 11836\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8731908097815179"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RMSE DF Test (55000) Train (220000)\n",
    "\n",
    "error_df_br = data_concat.sub(train)\n",
    "error_df_br_abs = error_df_br ** 2\n",
    "error = error_df_br_abs.sum().sum() / 220000\n",
    "np.sqrt(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = automated_sub_func_melt(data_imputer, submission)\n",
    "submission[\"value\"] = submission[\"row-col\"].apply(lambda item: data_concat.iloc[int(item.split(\"-\")[0])][item.split(\"-\")[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row-col</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-F_1_14</td>\n",
       "      <td>-0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-F_3_23</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-F_3_24</td>\n",
       "      <td>-0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-F_1_2</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-F_4_2</td>\n",
       "      <td>0.322784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999993-F_4_2</td>\n",
       "      <td>-0.114520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999994-F_3_10</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999994-F_4_9</td>\n",
       "      <td>-0.134452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999997-F_3_14</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999997-F_4_8</td>\n",
       "      <td>-0.145696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row-col     value\n",
       "0            0-F_1_14 -0.000905\n",
       "1            0-F_3_23  0.000365\n",
       "2            1-F_3_24 -0.000817\n",
       "3             2-F_1_2  0.000551\n",
       "4             2-F_4_2  0.322784\n",
       "...               ...       ...\n",
       "999995   999993-F_4_2 -0.114520\n",
       "999996  999994-F_3_10  0.001706\n",
       "999997   999994-F_4_9 -0.134452\n",
       "999998  999997-F_3_14  0.000727\n",
       "999999   999997-F_4_8 -0.145696\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count of NA per row\n",
    "\n",
    "na_cnt = pd.DataFrame(data_col[4].isna().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    759268\n",
       "1    211342\n",
       "2     27127\n",
       "3      2124\n",
       "4       135\n",
       "5         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cnt.groupby([0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272528"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col[4].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_4_0</th>\n",
       "      <th>F_4_1</th>\n",
       "      <th>F_4_2</th>\n",
       "      <th>F_4_3</th>\n",
       "      <th>F_4_4</th>\n",
       "      <th>F_4_5</th>\n",
       "      <th>F_4_6</th>\n",
       "      <th>F_4_7</th>\n",
       "      <th>F_4_8</th>\n",
       "      <th>F_4_9</th>\n",
       "      <th>F_4_10</th>\n",
       "      <th>F_4_11</th>\n",
       "      <th>F_4_12</th>\n",
       "      <th>F_4_13</th>\n",
       "      <th>F_4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225098</th>\n",
       "      <td>0.268807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.075833</td>\n",
       "      <td>0.274833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.322828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751367</td>\n",
       "      <td>0.726863</td>\n",
       "      <td>1.349478</td>\n",
       "      <td>0.701888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.243863</td>\n",
       "      <td>1.179875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604135</th>\n",
       "      <td>1.473255</td>\n",
       "      <td>-2.091601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321455</td>\n",
       "      <td>2.944792</td>\n",
       "      <td>-0.845840</td>\n",
       "      <td>-0.976769</td>\n",
       "      <td>-1.096915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.935633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.229738</td>\n",
       "      <td>1.112853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857976</th>\n",
       "      <td>-1.640267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.320024</td>\n",
       "      <td>-0.344264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.175051</td>\n",
       "      <td>0.118577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.072447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.613657</td>\n",
       "      <td>-0.566197</td>\n",
       "      <td>-0.050125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886281</th>\n",
       "      <td>1.467103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823892</td>\n",
       "      <td>-0.273274</td>\n",
       "      <td>0.560576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.484972</td>\n",
       "      <td>0.720048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>-0.093264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.919703</td>\n",
       "      <td>-5.173954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F_4_0     F_4_1     F_4_2     F_4_3     F_4_4     F_4_5     F_4_6  \\\n",
       "225098  0.268807       NaN -0.075833  0.274833       NaN -4.322828       NaN   \n",
       "604135  1.473255 -2.091601       NaN  0.321455  2.944792 -0.845840 -0.976769   \n",
       "857976 -1.640267       NaN  0.355139       NaN -1.320024 -0.344264       NaN   \n",
       "886281  1.467103       NaN  0.823892 -0.273274  0.560576       NaN -3.484972   \n",
       "\n",
       "           F_4_7     F_4_8     F_4_9    F_4_10    F_4_11    F_4_12    F_4_13  \\\n",
       "225098       NaN  0.751367  0.726863  1.349478  0.701888       NaN  2.243863   \n",
       "604135 -1.096915       NaN       NaN       NaN  5.935633       NaN  2.229738   \n",
       "857976  2.175051  0.118577       NaN -0.072447       NaN -2.613657 -0.566197   \n",
       "886281  0.720048       NaN  0.290900 -0.093264       NaN -2.919703 -5.173954   \n",
       "\n",
       "          F_4_14  \n",
       "225098  1.179875  \n",
       "604135  1.112853  \n",
       "857976 -0.050125  \n",
       "886281       NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\4211179680.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 1] = data_completed_1[data_col[4].isna().sum(axis=1) == 1]\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\4211179680.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 1] = data_completed_1[data_col[4].isna().sum(axis=1) == 1]\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 1] = data_completed_1[data_col[4].isna().sum(axis=1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\1994812681.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 2] = data_completed[data_col[4].isna().sum(axis=1) == 2]\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\1994812681.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 2] = data_completed[data_col[4].isna().sum(axis=1) == 2]\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 2] = data_completed[data_col[4].isna().sum(axis=1) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\674399112.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 3] = data_completed[data_col[4].isna().sum(axis=1) == 3]\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\674399112.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 3] = data_completed[data_col[4].isna().sum(axis=1) == 3]\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 3] = data_completed[data_col[4].isna().sum(axis=1) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\3030648619.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 4] = data_completed[data_col[4].isna().sum(axis=1) == 4]\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\3030648619.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 4] = data_completed[data_col[4].isna().sum(axis=1) == 4]\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 4] = data_completed[data_col[4].isna().sum(axis=1) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\2573207123.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 5] = data_completed[data_col[4].isna().sum(axis=1) == 5]\n",
      "C:\\Users\\U351473\\AppData\\Local\\Temp\\ipykernel_96836\\2573207123.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_col[4][data_col[4].isna().sum(axis=1) == 5] = data_completed[data_col[4].isna().sum(axis=1) == 5]\n"
     ]
    }
   ],
   "source": [
    "data_col[4][data_col[4].isna().sum(axis=1) == 5] = data_completed[data_col[4].isna().sum(axis=1) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_concat.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concat = pd.concat([data_col[1], data_col[2], data_col[3], data_col[4]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = automated_sub_func_melt(data_imputer, submission)\n",
    "submission[\"value\"] = submission[\"row-col\"].apply(lambda item: data_concat.iloc[int(item.split(\"-\")[0])][item.split(\"-\")[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row-col</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-F_1_14</td>\n",
       "      <td>-0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-F_3_23</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-F_3_24</td>\n",
       "      <td>-0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-F_1_2</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-F_4_2</td>\n",
       "      <td>0.360833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999993-F_4_2</td>\n",
       "      <td>-0.139782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999994-F_3_10</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999994-F_4_9</td>\n",
       "      <td>-0.134005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999997-F_3_14</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999997-F_4_8</td>\n",
       "      <td>-0.129129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row-col     value\n",
       "0            0-F_1_14 -0.000905\n",
       "1            0-F_3_23  0.000365\n",
       "2            1-F_3_24 -0.000817\n",
       "3             2-F_1_2  0.000551\n",
       "4             2-F_4_2  0.360833\n",
       "...               ...       ...\n",
       "999995   999993-F_4_2 -0.139782\n",
       "999996  999994-F_3_10  0.001706\n",
       "999997   999994-F_4_9 -0.134005\n",
       "999998  999997-F_3_14  0.000727\n",
       "999999   999997-F_4_8 -0.129129\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2fe89c37f1ba5abdad09d6b29cf31ae7cdfbf11664c9aad9198282e6781c441"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
